{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO7TzGm16GJG",
        "outputId": "05fb6732-1a71-4b63-e1e4-b0cf5c19cedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum objective function: -0.9293009314259595\n",
            "x1, x2 when having minumum objective function: [-0.24991534  0.69172499]\n",
            "solution x1, x2: [[ 0.45766224 -1.2007455 ]\n",
            " [-2.29899637 -1.0118714 ]\n",
            " [-2.60304181 -0.59318565]\n",
            " [-0.56685031 -1.20127258]\n",
            " [-1.19064565 -0.75275637]\n",
            " [ 0.11249256 -1.78372093]\n",
            " [-2.82738315  1.99018875]\n",
            " [-1.334834   -1.12495456]\n",
            " [ 2.04542842 -0.54624396]\n",
            " [ 1.85816847  0.92140323]\n",
            " [-2.38817972 -0.49028772]\n",
            " [ 2.93281231  0.37968543]\n",
            " [-1.66987967 -0.69303279]\n",
            " [-2.87925922 -0.5170356 ]\n",
            " [-0.75984935  1.92147004]\n",
            " [ 1.60846964 -1.12200857]\n",
            " [ 0.55573341 -1.74414876]\n",
            " [-2.75476971  0.48295992]\n",
            " [-0.24991534  0.69172499]\n",
            " [ 1.09139514 -0.92622979]\n",
            " [-2.99893894  1.83440453]\n",
            " [-2.99871842  1.5821012 ]\n",
            " [-2.99925645  1.94245581]\n",
            " [-2.99173228  1.9788082 ]\n",
            " [-2.99545724  1.98357872]\n",
            " [ 2.99789075  1.99496589]\n",
            " [ 2.99826932  1.62972277]\n",
            " [ 2.7832719   1.99971627]\n",
            " [ 2.99788634 -1.98192986]\n",
            " [ 2.99511813 -1.511444  ]\n",
            " [ 2.53395185 -1.99993587]\n",
            " [-2.98702191 -1.98958832]\n",
            " [-2.99914816 -1.703832  ]\n",
            " [-2.75840755 -1.99952109]\n",
            " [ 2.99886759  1.95510315]\n",
            " [ 0.66018634  1.99997763]\n",
            " [ 2.99764213 -0.58227119]\n",
            " [ 2.99714736  1.07201292]\n",
            " [-2.99847489 -1.93325248]\n",
            " [-2.99539509 -1.15548443]\n",
            " [-1.73257635  1.99613767]\n",
            " [ 2.99946742  1.99972615]\n",
            " [ 1.64262977  1.99878666]\n",
            " [-1.16301959 -1.99968101]\n",
            " [-1.60084744  0.88384974]\n",
            " [-2.99865009  1.04449707]\n",
            " [ 2.99551647 -0.12831153]\n",
            " [ 2.99957824 -1.83103643]\n",
            " [ 1.43702512 -1.9970305 ]\n",
            " [ 0.76267712  1.01262029]]\n",
            "objective function: [ 2.74708814e+00  1.41177822e+01  3.50171888e+01  4.31787735e+00\n",
            "  2.31389251e+00  2.76148366e+01  1.09346697e+02  5.19145615e+00\n",
            "  2.43295648e+00  3.69585803e+00  1.67852427e+01  9.17807858e+01\n",
            "  2.21133988e+00  7.94572814e+01  3.99702221e+01  1.56381996e+00\n",
            "  2.49237664e+01  5.30486907e+01 -9.29300931e-01  8.49878101e-01\n",
            "  1.34932388e+02  1.18842009e+02  1.44717308e+02  1.46326166e+02\n",
            "  1.47863334e+02  1.61723172e+02  1.30890384e+02  1.13457193e+02\n",
            "  1.48367127e+02  1.14734761e+02  7.02703825e+01  1.58060829e+02\n",
            "  1.35867491e+02  1.09154594e+02  1.57596896e+02  5.06899151e+01\n",
            "  1.05592086e+02  1.11993418e+02  1.55190308e+02  1.12853140e+02\n",
            "  4.62110598e+01  1.62716707e+02  5.31995978e+01  5.26832194e+01\n",
            " -2.93259627e-02  1.05783164e+02  1.07187062e+02  1.34839736e+02\n",
            "  4.70387624e+01  2.55826127e+00]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import sklearn.gaussian_process as gp\n",
        "\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def improvement(x, gaussian_process, evaluated_loss, greater_is_better=False, n_params=1):\n",
        "\n",
        "    x_to_predict = x.reshape(-1, n_params)\n",
        "\n",
        "    mu, sigma = gaussian_process.predict(x_to_predict, return_std=True)\n",
        "\n",
        "    if greater_is_better:\n",
        "        loss_optimum = np.max(evaluated_loss)\n",
        "    else:\n",
        "        loss_optimum = np.min(evaluated_loss)\n",
        "\n",
        "    scaling_factor = (-1) ** (not greater_is_better)\n",
        "\n",
        "    # In case sigma equals zero\n",
        "    with np.errstate(divide='ignore'):\n",
        "        Z = scaling_factor * (mu - loss_optimum) / sigma\n",
        "        improvement = scaling_factor * (mu - loss_optimum) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
        "        improvement[sigma == 0.0] == 0.0\n",
        "\n",
        "    return -1 * improvement\n",
        "\n",
        "\n",
        "def hyperparameter(acquisition_func, gaussian_process, evaluated_loss, greater_is_better=False,\n",
        "                               bounds=(0, 10), n_restarts=25):\n",
        "\n",
        "    best_x = None\n",
        "    best_acquisition_value = 1\n",
        "    n_params = bounds.shape[0]\n",
        "\n",
        "    for starting_point in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, n_params)):\n",
        "\n",
        "        res = minimize(fun=acquisition_func,\n",
        "                       x0=starting_point.reshape(1, -1),\n",
        "                       bounds=bounds,\n",
        "                       method='L-BFGS-B',\n",
        "                       args=(gaussian_process, evaluated_loss, greater_is_better, n_params))\n",
        "\n",
        "        if res.fun < best_acquisition_value:\n",
        "            best_acquisition_value = res.fun\n",
        "            best_x = res.x\n",
        "\n",
        "    return best_x\n",
        "\n",
        "\n",
        "def bayesian_optimisation(n_iters, sample_loss, bounds, x0=None, n_pre_samples=5,\n",
        "                          gp_params=None, random_search=False, alpha=1e-5, epsilon=1e-7):\n",
        "\n",
        "    x_list = []\n",
        "    y_list = []\n",
        "\n",
        "    n_params = bounds.shape[0]\n",
        "\n",
        "    if x0 is None:\n",
        "        for params in np.random.uniform(bounds[:, 0], bounds[:, 1], (n_pre_samples, bounds.shape[0])):\n",
        "            x_list.append(params)\n",
        "            y_list.append(sample_loss(params))\n",
        "            # print()\n",
        "    else:\n",
        "        for params in x0:\n",
        "            x_list.append(params)\n",
        "            y_list.append(sample_loss(params))\n",
        "\n",
        "    xp = np.array(x_list)\n",
        "    yp = np.array(y_list)\n",
        "\n",
        "    # Create the GP\n",
        "    if gp_params is not None:\n",
        "        model = gp.GaussianProcessRegressor(**gp_params)\n",
        "    else:\n",
        "        kernel = gp.kernels.Matern()\n",
        "        model = gp.GaussianProcessRegressor(kernel=kernel,\n",
        "                                            alpha=alpha,\n",
        "                                            n_restarts_optimizer=10,\n",
        "                                            normalize_y=True)\n",
        "\n",
        "    for n in range(n_iters):\n",
        "\n",
        "        model.fit(xp, yp)\n",
        "\n",
        "        # Sample next hyperparameter\n",
        "        if random_search:\n",
        "            x_random = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(random_search, n_params))\n",
        "            ei = -1 * improvement(x_random, model, yp, greater_is_better=True, n_params=n_params)\n",
        "            next_sample = x_random[np.argmax(ei), :]\n",
        "        else:\n",
        "            next_sample = hyperparameter(improvement, model, yp, greater_is_better=True, bounds=bounds, n_restarts=100)\n",
        "\n",
        "        # Duplicates will break the GP. In case of a duplicate, we will randomly sample a next query point.\n",
        "        if np.any(np.abs(next_sample - xp) <= epsilon):\n",
        "            next_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], bounds.shape[0])\n",
        "\n",
        "        # Sample loss for new set of parameters\n",
        "        cv_score = sample_loss(next_sample)\n",
        "\n",
        "        # Update lists\n",
        "        x_list.append(next_sample)\n",
        "        y_list.append(cv_score)\n",
        "\n",
        "        # Update xp and yp\n",
        "        xp = np.array(x_list)\n",
        "        yp = np.array(y_list)\n",
        "\n",
        "    return xp, yp\n",
        "\n",
        "def sample_loss(params):\n",
        "\n",
        "    return (4 - 2.1 * params[0] ** 2 + params[0] ** 4 / 3) * params[0] ** 2 + params[0] * params[1] + (-4 + 4 * params[1] ** 2) * params[1] ** 2\n",
        "\n",
        "bounds = np.array([[-3, 3], [-2, 2]])\n",
        "\n",
        "xp, yp = bayesian_optimisation(n_iters=30,\n",
        "                               sample_loss=sample_loss,\n",
        "                               bounds=bounds,\n",
        "                               n_pre_samples=20,\n",
        "                               random_search=100000)\n",
        "\n",
        "print('minimum objective function:', np.min(yp))\n",
        "print('x1, x2 when having minumum objective function:',xp[np.argmin(yp)])\n",
        "print('solution x1, x2:', xp)\n",
        "print('objective function:', yp)"
      ]
    }
  ]
}